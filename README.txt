# CPU LLM

## :warning: Highly experimental :warning

LLM built from the ground-up to use CPUs (multiple threads) and CPU RAM instead of GPUs and GPU RAM.

Unlike other existing solutions (circa 2025), the aim is not to take GPU-centric models and limit them to work on CPUs; it's to build something from the ground-up that's made to run efficiently on CPUs.

